 This article is about cognition. For other uses, see Consciousness (disambiguation) and Conscious (disambiguation).




                                         Representation of consciousness from
                                         the seventeenth century by Robert
                                         Fludd, an English Paracelsian
                                         physician

Consciousness is the state or quality of awareness or of being aware of an external object or
something within oneself.[1][2] It has been deﬁned variously in terms of sentience, awareness, qualia,
subjectivity, the ability to experience or to feel, wakefulness, having a sense of selfhood or soul, the
fact that there is something "that it is like" to "have" or "be" it, and the executive control system of
the mind.[3] Despite the diﬃculty in deﬁnition, many philosophers believe that there is a broadly
shared underlying intuition about what consciousness is.[4] As Max Velmans and Susan Schneider
wrote in The Blackwell Companion to Consciousness: "Anything that we are aware of at a given
moment forms part of our consciousness, making conscious experience at once the most familiar
and most mysterious aspect of our lives."[5]

Western philosophers, since the time of Descartes and Locke, have struggled to comprehend the
nature of consciousness and identify its essential properties. Issues of concern in the philosophy of
consciousness include whether the concept is fundamentally coherent; whether consciousness can
ever be explained mechanistically; whether non-human consciousness exists and if so how it can
be recognized; how consciousness relates to language; whether consciousness can be understood
in a way that does not require a dualistic distinction between mental and physical states or
properties; and whether it may ever be possible for computing machines like computers or robots to
be conscious, a topic studied in the ﬁeld of artiﬁcial intelligence.

Thanks to developments in technology over the past few decades, consciousness has become a
signiﬁcant topic of interdisciplinary research in cognitive science, with signiﬁcant contributions
from ﬁelds such as psychology, anthropology,[6][7] neuropsychology and neuroscience. The primary
focus is on understanding what it means biologically and psychologically for information to be
present in consciousness—that is, on determining the neural and psychological correlates of
consciousness. The majority of experimental studies assess consciousness in humans by asking
subjects for a verbal report of their experiences (e.g., "tell me if you notice anything when I do this").
Issues of interest include phenomena such as subliminal perception, blindsight, denial of
impairment, and altered states of consciousness produced by alcohol and other drugs, or spiritual
or meditative techniques.

In medicine, consciousness is assessed by observing a patient's arousal and responsiveness, and
can be seen as a continuum of states ranging from full alertness and comprehension, through
disorientation, delirium, loss of meaningful communication, and ﬁnally loss of movement in
response to painful stimuli.[8] Issues of practical concern include how the presence of
consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat
conditions in which consciousness is impaired or disrupted.[9] The degree of consciousness is
measured by standardized behavior observation scales such as the Glasgow Coma Scale.


Etymology




                                         John Locke, British
                                         philosopher active in the
                                         17th century

The origin of the modern concept of consciousness is often attributed to John Locke's Essay
Concerning Human Understanding, published in 1690.[10] Locke deﬁned consciousness as "the
perception of what passes in a man's own mind".[11] His essay inﬂuenced the 18th-century view of
consciousness, and his deﬁnition appeared in Samuel Johnson's celebrated Dictionary (1755).[12]
"Consciousness" (French: conscience) is also deﬁned in the 1753 volume of Diderot and
d'Alembert's Encyclopédie, as "the opinion or internal feeling that we ourselves have from what we
do".[13]
The earliest English language uses of "conscious" and "consciousness" date back, however, to the
1500s. The English word "conscious" originally derived from the Latin conscius (con- "together" and
scio "to know"), but the Latin word did not have the same meaning as our word—it meant "knowing
with", in other words "having joint or common knowledge with another".[14] There were, however,
many occurrences in Latin writings of the phrase conscius sibi, which translates literally as "knowing
with oneself", or in other words "sharing knowledge with oneself about something". This phrase had
the ﬁgurative meaning of "knowing that one knows", as the modern English word "conscious" does.
In its earliest uses in the 1500s, the English word "conscious" retained the meaning of the Latin
conscius. For example, Thomas Hobbes in Leviathan wrote: "Where two, or more men, know of one
and the same fact, they are said to be Conscious of it one to another."[15] The Latin phrase conscius
sibi, whose meaning was more closely related to the current concept of consciousness, was
rendered in English as "conscious to oneself" or "conscious unto oneself". For example, Archbishop
Ussher wrote in 1613 of "being so conscious unto myself of my great weakness".[16] Locke's
deﬁnition from 1690 illustrates that a gradual shift in meaning had taken place.

A related word was conscientia, which primarily means moral conscience. In the literal sense,
"conscientia" means knowledge-with, that is, shared knowledge. The word ﬁrst appears in Latin
juridical texts by writers such as Cicero.[17] Here, conscientia is the knowledge that a witness has of
the deed of someone else.[18] René Descartes (1596–1650) is generally taken to be the ﬁrst
philosopher to use conscientia in a way that does not ﬁt this traditional meaning.[19] Descartes used
conscientia the way modern speakers would use "conscience". In Search after Truth (Regulæ ad
directionem ingenii ut et inquisitio veritatis per lumen naturale, Amsterdam 1701) he says
"conscience or internal testimony" (conscientiâ, vel interno testimonio).[20][21]


Dictionary deﬁnitions

The dictionary meanings of the word consciousness extend through several centuries and several
associated related meanings. These have ranged from formal deﬁnitions to deﬁnitions attempting
to capture the less easily captured and more debated meanings and usage of the word.

One formal deﬁnition indicating the range of these related meanings is given in Webster's Third New
International Dictionary stating that consciousness is:

  1.      awareness or perception of an inward psychological or spiritual fact: intuitively perceived
          knowledge of something in one's inner self

          inward awareness of an external object, state, or fact

          concerned awareness: INTEREST, CONCERN—often used with an attributive noun.
  2. the state or activity that is characterized by sensation, emotion, volition, or thought: mind in the
     broadest possible sense: something in nature that is distinguished from the physical.

  3. the totality in psychology of sensations, perceptions, ideas, attitudes and feelings of which an
     individual or a group is aware at any given time or within a particular time span—compare
     STREAM OF CONSCIOUSNESS."

The Cambridge Dictionary deﬁnes consciousness as "the state of understanding and realizing
something."[22] The Oxford Living Dictionary deﬁnes consciousness as "The state of being aware of
and responsive to one's surroundings.", "A person's awareness or perception of something." and "The
fact of awareness by the mind of itself and the world."[23]

Most deﬁnitions include awareness, but some include a more general state of being.


Philosophy of mind

The philosophy of mind has given rise to many stances regarding consciousness. The Routledge
Encyclopedia of Philosophy in 1998 deﬁnes consciousness as follows:


      Consciousness—Philosophers have used the term 'consciousness' for four
      main topics: knowledge in general, intentionality, introspection (and the
      knowledge it speciﬁcally generates) and phenomenal experience...
      Something within one's mind is 'introspectively conscious' just in case one
      introspects it (or is poised to do so). Introspection is often thought to
      deliver one's primary knowledge of one's mental life. An experience or
      other mental entity is 'phenomenally conscious' just in case there is
      'something it is like' for one to have it. The clearest examples are:
      perceptual experience, such as tastings and seeings; bodily-sensational
      experiences, such as those of pains, tickles and itches; imaginative
      experiences, such as those of one's own actions or perceptions; and
      streams of thought, as in the experience of thinking 'in words' or 'in
      images'. Introspection and phenomenality seem independent, or
      dissociable, although this is controversial.[24]


In a more skeptical deﬁnition of consciousness, Stuart Sutherland has exempliﬁed some of the
diﬃculties in fully ascertaining all of its cognate meanings in his entry for the 1989 version of the
Macmillan Dictionary of Psychology:
      Consciousness—The having of perceptions, thoughts, and feelings;
      awareness. The term is impossible to deﬁne except in terms that are
      unintelligible without a grasp of what consciousness means. Many fall into
      the trap of equating consciousness with self-consciousness—to be
      conscious it is only necessary to be aware of the external world.
      Consciousness is a fascinating but elusive phenomenon: it is impossible to
      specify what it is, what it does, or why it has evolved. Nothing worth
      reading has been written on it.[25]


Most writers on the philosophy of consciousness have been concerned with defending a particular
point of view, and have organized their material accordingly. For surveys, the most common
approach is to follow a historical path by associating stances with the philosophers who are most
strongly associated with them, for example Descartes, Locke, Kant, etc. An alternative is to organize
philosophical stances according to basic issues.


The coherence of the concept

Philosophers and non-philosophers differ in their intuitions about what consciousness is.[26] While
most people have a strong intuition for the existence of what they refer to as consciousness,[27]
skeptics argue that this intuition is false, either because the concept of consciousness is
intrinsically incoherent, or because our intuitions about it are based in illusions. Gilbert Ryle, for
example, argued that traditional understanding of consciousness depends on a Cartesian dualist
outlook that improperly distinguishes between mind and body, or between mind and world. He
proposed that we speak not of minds, bodies, and the world, but of individuals, or persons, acting in
the world. Thus, by speaking of "consciousness" we end up misleading ourselves by thinking that
there is any sort of thing as consciousness separated from behavioral and linguistic
understandings.[28] More generally, many philosophers and scientists have been unhappy about the
diﬃculty of producing a deﬁnition that does not involve circularity or fuzziness.[25]


Types of consciousness

Many philosophers have argued that consciousness is a unitary concept that is understood
intuitively by the majority of people in spite of the diﬃculty in deﬁning it.[27] Others, though, have
argued that the level of disagreement about the meaning of the word indicates that it either means
different things to different people (for instance, the objective versus subjective aspects of
consciousness), or else is an umbrella term encompassing a variety of distinct meanings with no
simple element in common.[29]

Ned Block proposed a distinction between two types of consciousness that he called phenomenal
(P-consciousness) and access (A-consciousness).[30] P-consciousness, according to Block, is
simply raw experience: it is moving, colored forms, sounds, sensations, emotions and feelings with
our bodies' and responses at the center. These experiences, considered independently of any
impact on behavior, are called qualia. A-consciousness, on the other hand, is the phenomenon
whereby information in our minds is accessible for verbal report, reasoning, and the control of
behavior. So, when we perceive, information about what we perceive is access conscious; when we
introspect, information about our thoughts is access conscious; when we remember, information
about the past is access conscious, and so on. Although some philosophers, such as Daniel
Dennett, have disputed the validity of this distinction,[31] others have broadly accepted it. David
Chalmers has argued that A-consciousness can in principle be understood in mechanistic terms,
but that understanding P-consciousness is much more challenging: he calls this the hard problem
of consciousness.[32]

Some philosophers believe that Block's two types of consciousness are not the end of the story.
William Lycan, for example, argued in his book Consciousness and Experience that at least eight
clearly distinct types of consciousness can be identiﬁed (organism consciousness; control
consciousness; consciousness of; state/event consciousness; reportability; introspective
consciousness; subjective consciousness; self-consciousness)—and that even this list omits
several more obscure forms.[33]

There is also debate over whether or not A-consciousness and P-consciousness always coexist or if
they can exist separately. Although P-consciousness without A-consciousness is more widely
accepted, there have been some hypothetical examples of A without P. Block for instance suggests
the case of a “zombie” that is computationally identical to a person but without any subjectivity.
However, he remains somewhat skeptical concluding "I don’t know whether there are any actual
cases of A-consciousness without P-consciousness, but I hope I have illustrated their conceptual
possibility." [34]


Mind–body problem
 Main article: Mind–body problem
                                    Illustration of dualism by René
                                    Descartes. Inputs are passed by
                                    the sensory organs to the pineal
                                    gland and from there to the
                                    immaterial spirit.

Mental processes (such as consciousness) and physical processes (such as brain events) seem to
be correlated, however the speciﬁc nature of the connection is unknown.

The ﬁrst inﬂuential philosopher to discuss this question speciﬁcally was Descartes, and the answer
he gave is known as Cartesian dualism. Descartes proposed that consciousness resides within an
immaterial domain he called res cogitans (the realm of thought), in contrast to the domain of
material things, which he called res extensa (the realm of extension).[35] He suggested that the
interaction between these two domains occurs inside the brain, perhaps in a small midline structure
called the pineal gland.[36]

Although it is widely accepted that Descartes explained the problem cogently, few later
philosophers have been happy with his solution, and his ideas about the pineal gland have
especially been ridiculed.[37] However, no alternative solution has gained general acceptance.
Proposed solutions can be divided broadly into two categories: dualist solutions that maintain
Descartes' rigid distinction between the realm of consciousness and the realm of matter but give
different answers for how the two realms relate to each other; and monist solutions that maintain
that there is really only one realm of being, of which consciousness and matter are both aspects.
Each of these categories itself contains numerous variants. The two main types of dualism are
substance dualism (which holds that the mind is formed of a distinct type of substance not
governed by the laws of physics) and property dualism (which holds that the laws of physics are
universally valid but cannot be used to explain the mind). The three main types of monism are
physicalism (which holds that the mind consists of matter organized in a particular way), idealism
(which holds that only thought or experience truly exists, and matter is merely an illusion), and
neutral monism (which holds that both mind and matter are aspects of a distinct essence that is
itself identical to neither of them). There are also, however, a large number of idiosyncratic theories
that cannot cleanly be assigned to any of these schools of thought.[38]

Since the dawn of Newtonian science with its vision of simple mechanical principles governing the
entire universe, some philosophers have been tempted by the idea that consciousness could be
explained in purely physical terms. The ﬁrst inﬂuential writer to propose such an idea explicitly was
Julien Offray de La Mettrie, in his book Man a Machine (L'homme machine). His arguments, however,
were very abstract.[39] The most inﬂuential modern physical theories of consciousness are based on
psychology and neuroscience. Theories proposed by neuroscientists such as Gerald Edelman[40]
and Antonio Damasio,[41] and by philosophers such as Daniel Dennett,[42] seek to explain
consciousness in terms of neural events occurring within the brain. Many other neuroscientists,
such as Christof Koch,[43] have explored the neural basis of consciousness without attempting to
frame all-encompassing global theories. At the same time, computer scientists working in the ﬁeld
of artiﬁcial intelligence have pursued the goal of creating digital computer programs that can
simulate or embody consciousness.[44]

A few theoretical physicists have argued that classical physics is intrinsically incapable of
explaining the holistic aspects of consciousness, but that quantum theory may provide the missing
ingredients. Several theorists have therefore proposed quantum mind (QM) theories of
consciousness.[45] Notable theories falling into this category include the holonomic brain theory of
Karl Pribram and David Bohm, and the Orch-OR theory formulated by Stuart Hameroff and Roger
Penrose. Some of these QM theories offer descriptions of phenomenal consciousness, as well as
QM interpretations of access consciousness. None of the quantum mechanical theories have been
conﬁrmed by experiment. Recent publications by G. Guerreshi, J. Cia, S. Popescu, and H. Briegel[46]
could falsify proposals such as those of Hameroff, which rely on quantum entanglement in protein.
At the present time many scientists and philosophers consider the arguments for an important role
of quantum phenomena to be unconvincing.[47]

Apart from the general question of the "hard problem" of consciousness, roughly speaking, the
question of how mental experience arises from a physical basis,[48] a more specialized question is
how to square the subjective notion that we are in control of our decisions (at least in some small
measure) with the customary view of causality that subsequent events are caused by prior events.
The topic of free will is the philosophical and scientiﬁc examination of this conundrum.


Problem of other minds
 Main article: Problem of other minds
Many philosophers consider experience to be the essence of consciousness, and believe that
experience can only fully be known from the inside, subjectively. But if consciousness is subjective
and not visible from the outside, why do the vast majority of people believe that other people are
conscious, but rocks and trees are not?[49] This is called the problem of other minds.[50] It is
particularly acute for people who believe in the possibility of philosophical zombies, that is, people
who think it is possible in principle to have an entity that is physically indistinguishable from a
human being and behaves like a human being in every way but nevertheless lacks
consciousness.[51] Related issues have also been studied extensively by Greg Littmann of the
University of Illinois,[52] and Colin Allen a professor at Indiana University regarding the literature and
research studying artiﬁcial intelligence in androids.[53]

The most commonly given answer is that we attribute consciousness to other people because we
see that they resemble us in appearance and behavior; we reason that if they look like us and act
like us, they must be like us in other ways, including having experiences of the sort that we do.[54]
There are, however, a variety of problems with that explanation. For one thing, it seems to violate the
principle of parsimony, by postulating an invisible entity that is not necessary to explain what we
observe.[54] Some philosophers, such as Daniel Dennett in an essay titled The Unimagined
Preposterousness of Zombies, argue that people who give this explanation do not really understand
what they are saying.[55] More broadly, philosophers who do not accept the possibility of zombies
generally believe that consciousness is reﬂected in behavior (including verbal behavior), and that we
attribute consciousness on the basis of behavior. A more straightforward way of saying this is that
we attribute experiences to people because of what they can do, including the fact that they can tell
us about their experiences.[56]



Animal consciousness
 See also: Animal consciousness

The topic of animal consciousness is beset by a number of diﬃculties. It poses the problem of
other minds in an especially severe form, because non-human animals, lacking the ability to express
human language, cannot tell us about their experiences.[57] Also, it is diﬃcult to reason objectively
about the question, because a denial that an animal is conscious is often taken to imply that it does
not feel, its life has no value, and that harming it is not morally wrong. Descartes, for example, has
sometimes been blamed for mistreatment of animals due to the fact that he believed only humans
have a non-physical mind.[58] Most people have a strong intuition that some animals, such as cats
and dogs, are conscious, while others, such as insects, are not; but the sources of this intuition are
not obvious, and are often based on personal interactions with pets and other animals they have
observed.[57]
Philosophers who consider subjective experience the essence of consciousness also generally
believe, as a correlate, that the existence and nature of animal consciousness can never rigorously
be known. Thomas Nagel spelled out this point of view in an inﬂuential essay titled What Is it Like to
Be a Bat?. He said that an organism is conscious "if and only if there is something that it is like to be
that organism—something it is like for the organism"; and he argued that no matter how much we
know about an animal's brain and behavior, we can never really put ourselves into the mind of the
animal and experience its world in the way it does itself.[59] Other thinkers, such as Douglas
Hofstadter, dismiss this argument as incoherent.[60] Several psychologists and ethologists have
argued for the existence of animal consciousness by describing a range of behaviors that appear to
show animals holding beliefs about things they cannot directly perceive—Donald Griﬃn's 2001 book
Animal Minds reviews a substantial portion of the evidence.[61]

On July 7, 2012, eminent scientists from different branches of neuroscience gathered at the
University of Cambridge to celebrate the Francis Crick Memorial Conference, which deals with
consciousness in humans and pre-linguistic consciousness in nonhuman animals. After the
conference, they signed in the presence of Stephen Hawking, the 'Cambridge Declaration on
Consciousness', which summarizes the most important ﬁndings of the survey:

"We decided to reach a consensus and make a statement directed to the public that is not scientiﬁc.
It's obvious to everyone in this room that animals have consciousness, but it is not obvious to the
rest of the world. It is not obvious to the rest of the Western world or the Far East. It is not obvious
to the society."[62]

"Convergent evidence indicates that non-human animals [...], including all mammals and birds, and
other creatures, [...] have the necessary neural substrates of consciousness and the capacity to
exhibit intentional behaviors."[63]


Artifact consciousness
 See also: Artiﬁcial consciousness

The idea of an artifact made conscious is an ancient theme of mythology, appearing for example in
the Greek myth of Pygmalion, who carved a statue that was magically brought to life, and in
medieval Jewish stories of the Golem, a magically animated homunculus built of clay.[64] However,
the possibility of actually constructing a conscious machine was probably ﬁrst discussed by Ada
Lovelace, in a set of notes written in 1842 about the Analytical Engine invented by Charles Babbage,
a precursor (never built) to modern electronic computers. Lovelace was essentially dismissive of
the idea that a machine such as the Analytical Engine could think in a humanlike way. She wrote:
      It is desirable to guard against the possibility of exaggerated ideas that
      might arise as to the powers of the Analytical Engine. ... The Analytical
      Engine has no pretensions whatever to originate anything. It can do
      whatever we know how to order it to perform. It can follow analysis; but it
      has no power of anticipating any analytical relations or truths. Its
      province is to assist us in making available what we are already
      acquainted with.[65]


One of the most inﬂuential contributions to this question was an essay written in 1950 by
pioneering computer scientist Alan Turing, titled Computing Machinery and Intelligence. Turing
disavowed any interest in terminology, saying that even "Can machines think?" is too loaded with
spurious connotations to be meaningful; but he proposed to replace all such questions with a
speciﬁc operational test, which has become known as the Turing test.[66] To pass the test, a
computer must be able to imitate a human well enough to fool interrogators. In his essay Turing
discussed a variety of possible objections, and presented a counterargument to each of them. The
Turing test is commonly cited in discussions of artiﬁcial intelligence as a proposed criterion for
machine consciousness; it has provoked a great deal of philosophical debate. For example, Daniel
Dennett and Douglas Hofstadter argue that anything capable of passing the Turing test is
necessarily conscious,[67] while David Chalmers argues that a philosophical zombie could pass the
test, yet fail to be conscious.[68] A third group of scholars have argued that with technological
growth once machines begin to display any substantial signs of human-like behavior then the
dichotomy (of human consciousness compared to human-like consciousness) becomes passé and
issues of machine autonomy begin to prevail even as observed in its nascent form within
contemporary industry and technology.[52][53] Jürgen Schmidhuber argues that consciousness is
simply the result of compression.[69] As an agent sees representation of itself recurring in the
environment, the compression of this representation can be called consciousness.

In a lively exchange over what has come to be referred to as "the Chinese room argument", John
Searle sought to refute the claim of proponents of what he calls "strong artiﬁcial intelligence (AI)"
that a computer program can be conscious, though he does agree with advocates of "weak AI" that
computer programs can be formatted to "simulate" conscious states. His own view is that
consciousness has subjective, ﬁrst-person causal powers by being essentially intentional due
simply to the way human brains function biologically; conscious persons can perform
computations, but consciousness is not inherently computational the way computer programs are.
To make a Turing machine that speaks Chinese, Searle imagines a room with one monolingual
English speaker (Searle himself, in fact), a book that designates a combination of Chinese symbols
to be output paired with Chinese symbol input, and boxes ﬁlled with Chinese symbols. In this case,
the English speaker is acting as a computer and the rulebook as a program. Searle argues that with
such a machine, he would be able to process the inputs to outputs perfectly without having any
understanding of Chinese, nor having any idea what the questions and answers could possibly
mean. If the experiment were done in English, since Searle knows English, he would be able to take
questions and give answers without any algorithms for English questions, and he would be
effectively aware of what was being said and the purposes it might serve. Searle would pass the
Turing test of answering the questions in both languages, but he is only conscious of what he is
doing when he speaks English. Another way of putting the argument is to say that computer
programs can pass the Turing test for processing the syntax of a language, but that the syntax
cannot lead to semantic meaning in the way strong AI advocates hoped.[70][71]

In the literature concerning artiﬁcial intelligence, Searle's essay has been second only to Turing's in
the volume of debate it has generated.[72] Searle himself was vague about what extra ingredients it
would take to make a machine conscious: all he proposed was that what was needed was "causal
powers" of the sort that the brain has and that computers lack. But other thinkers sympathetic to his
basic argument have suggested that the necessary (though perhaps still not suﬃcient) extra
conditions may include the ability to pass not just the verbal version of the Turing test, but the
robotic version,[73] which requires grounding the robot's words in the robot's sensorimotor capacity
to categorize and interact with the things in the world that its words are about, Turing-
indistinguishably from a real person. Turing-scale robotics is an empirical branch of research on
embodied cognition and situated cognition.[74]

In 2014, Victor Argonov has suggested a non-Turing test for machine consciousness based on
machine's ability to produce philosophical judgments.[75] He argues that a deterministic machine
must be regarded as conscious if it is able to produce judgments on all problematic properties of
consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on
these issues, no philosophical discussions while learning, and no informational models of other
creatures in its memory (such models may implicitly or explicitly contain knowledge about these
creatures’ consciousness). However, this test can be used only to detect, but not refute the
existence of consciousness. A positive result proves that machine is conscious but a negative
result proves nothing. For example, absence of philosophical judgments may be caused by lack of
the machine’s intellect, not by absence of consciousness.


Scientiﬁc study

For many decades, consciousness as a research topic was avoided by the majority of mainstream
scientists, because of a general feeling that a phenomenon deﬁned in subjective terms could not
properly be studied using objective experimental methods.[76] In 1975 George Mandler published an
inﬂuential psychological study which distinguished between slow, serial, and limited conscious
processes and fast, parallel and extensive unconscious ones.[77] Starting in the 1980s, an expanding
community of neuroscientists and psychologists have associated themselves with a ﬁeld called
Consciousness Studies, giving rise to a stream of experimental work published in books,[78] journals
such as Consciousness and Cognition, Frontiers in Consciousness Research, Psyche, and the Journal
of Consciousness Studies, along with regular conferences organized by groups such as the
Association for the Scientiﬁc Study of Consciousness[79] and the Society for Consciousness
Studies.

Modern medical and psychological investigations into consciousness are based on psychological
experiments (including, for example, the investigation of priming effects using subliminal stimuli),
and on case studies of alterations in consciousness produced by trauma, illness, or drugs. Broadly
viewed, scientiﬁc approaches are based on two core concepts. The ﬁrst identiﬁes the content of
consciousness with the experiences that are reported by human subjects; the second makes use of
the concept of consciousness that has been developed by neurologists and other medical
professionals who deal with patients whose behavior is impaired. In either case, the ultimate goals
are to develop techniques for assessing consciousness objectively in humans as well as other
animals, and to understand the neural and psychological mechanisms that underlie it.[43]


Measurement




                                        The Necker cube, an
                                        ambiguous image

Experimental research on consciousness presents special diﬃculties, due to the lack of a
universally accepted operational deﬁnition. In the majority of experiments that are speciﬁcally about
consciousness, the subjects are human, and the criterion used is verbal report: in other words,
subjects are asked to describe their experiences, and their descriptions are treated as observations
of the contents of consciousness.[80] For example, subjects who stare continuously at a Necker
cube usually report that they experience it "ﬂipping" between two 3D conﬁgurations, even though the
stimulus itself remains the same.[81] The objective is to understand the relationship between the
conscious awareness of stimuli (as indicated by verbal report) and the effects the stimuli have on
brain activity and behavior. In several paradigms, such as the technique of response priming, the
behavior of subjects is clearly inﬂuenced by stimuli for which they report no awareness, and
suitable experimental manipulations can lead to increasing priming effects despite decreasing
prime identiﬁcation (double dissociation).[82]

Verbal report is widely considered to be the most reliable indicator of consciousness, but it raises a
number of issues.[83] For one thing, if verbal reports are treated as observations, akin to
observations in other branches of science, then the possibility arises that they may contain errors—
but it is diﬃcult to make sense of the idea that subjects could be wrong about their own
experiences, and even more diﬃcult to see how such an error could be detected.[84] Daniel Dennett
has argued for an approach he calls heterophenomenology, which means treating verbal reports as
stories that may or may not be true, but his ideas about how to do this have not been widely
adopted.[85] Another issue with verbal report as a criterion is that it restricts the ﬁeld of study to
humans who have language: this approach cannot be used to study consciousness in other species,
pre-linguistic children, or people with types of brain damage that impair language. As a third issue,
philosophers who dispute the validity of the Turing test may feel that it is possible, at least in
principle, for verbal report to be dissociated from consciousness entirely: a philosophical zombie
may give detailed verbal reports of awareness in the absence of any genuine awareness.[86]

Although verbal report is in practice the "gold standard" for ascribing consciousness, it is not the
only possible criterion.[83] In medicine, consciousness is assessed as a combination of verbal
behavior, arousal, brain activity and purposeful movement. The last three of these can be used as
indicators of consciousness when verbal behavior is absent.[87] The scientiﬁc literature regarding
the neural bases of arousal and purposeful movement is very extensive. Their reliability as
indicators of consciousness is disputed, however, due to numerous studies showing that alert
human subjects can be induced to behave purposefully in a variety of ways in spite of reporting a
complete lack of awareness.[82] Studies of the neuroscience of free will have also shown that the
experiences that people report when they behave purposefully sometimes do not correspond to
their actual behaviors or to the patterns of electrical activity recorded from their brains.[88]

Another approach applies speciﬁcally to the study of self-awareness, that is, the ability to
distinguish oneself from others. In the 1970s Gordon Gallup developed an operational test for self-
awareness, known as the mirror test. The test examines whether animals are able to differentiate
between seeing themselves in a mirror versus seeing other animals. The classic example involves
placing a spot of coloring on the skin or fur near the individual's forehead and seeing if they attempt
to remove it or at least touch the spot, thus indicating that they recognize that the individual they are
seeing in the mirror is themselves.[89] Humans (older than 18 months) and other great apes,
bottlenose dolphins, killer whales, pigeons, European magpies and elephants have all been
observed to pass this test.[90]



Neural correlates




                   Schema of the neural processes underlying consciousness, from Christof Koch

A major part of the scientiﬁc literature on consciousness consists of studies that examine the
relationship between the experiences reported by subjects and the activity that simultaneously
takes place in their brains—that is, studies of the neural correlates of consciousness. The hope is to
ﬁnd that activity in a particular part of the brain, or a particular pattern of global brain activity, which
will be strongly predictive of conscious awareness. Several brain imaging techniques, such as EEG
and fMRI, have been used for physical measures of brain activity in these studies.[91]

Another idea that has drawn attention for several decades is that consciousness is associated with
high-frequency (gamma band) oscillations in brain activity. This idea arose from proposals in the
1980s, by Christof von der Malsburg and Wolf Singer, that gamma oscillations could solve the so-
called binding problem, by linking information represented in different parts of the brain into a
uniﬁed experience.[92] Rodolfo Llinás, for example, proposed that consciousness results from
recurrent thalamo-cortical resonance where the speciﬁc thalamocortical systems (content) and the
non-speciﬁc (centromedial thalamus) thalamocortical systems (context) interact in the gamma
band frequency via synchronous oscillations.[93]

A number of studies have shown that activity in primary sensory areas of the brain is not suﬃcient
to produce consciousness: it is possible for subjects to report a lack of awareness even when areas
such as the primary visual cortex show clear electrical responses to a stimulus.[94] Higher brain
areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of
higher cognitive functions collectively known as executive functions. There is substantial evidence
that a "top-down" ﬂow of neural activity (i.e., activity propagating from the frontal cortex to sensory
areas) is more predictive of conscious awareness than a "bottom-up" ﬂow of activity.[95] The
prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his
colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe
reﬂect the visual perception in the situation when conﬂicting visual images are presented to
different eyes (i.e., bistable percepts during binocular rivalry).[96]

Modulation of neural responses may correlate with phenomenal experiences. In contrast to the raw
electrical responses that do not correlate with consciousness, the modulation of these responses
by other stimuli correlates surprisingly well with an important aspect of consciousness: namely with
the phenomenal experience of stimulus intensity (brightness, contrast). In the research group of
Danko Nikolić it has been shown that some of the changes in the subjectively perceived brightness
correlated with the modulation of ﬁring rates while others correlated with the modulation of neural
synchrony.[97] An fMRI investigation suggested that these ﬁndings were strictly limited to the
primary visual areas.[98] This indicates that, in the primary visual areas, changes in ﬁring rates and
synchrony can be considered as neural correlates of qualia—at least for some type of qualia.

In 2011, Graziano and Kastner[99] proposed the "attention schema" theory of awareness. In that
theory, speciﬁc cortical areas, notably in the superior temporal sulcus and the temporo-parietal
junction, are used to build the construct of awareness and attribute it to other people. The same
cortical machinery is also used to attribute awareness to oneself. Damage to these cortical regions
can lead to deﬁcits in consciousness such as hemispatial neglect. In the attention schema theory,
the value of explaining the feature of awareness and attributing it to a person is to gain a useful
predictive model of that person's attentional processing. Attention is a style of information
processing in which a brain focuses its resources on a limited set of interrelated signals.
Awareness, in this theory, is a useful, simpliﬁed schema that represents attentional states. To be
aware of X is explained by constructing a model of one's attentional focus on X.

In 2013, the perturbational complexity index (PCI) was proposed, a measure of the algorithmic
complexity of the electrophysiological response of the cortex to transcranial magnetic stimulation.
This measure was shown to be higher in individuals that are awake, in REM sleep or in a locked-in
state than in those who are in deep sleep or in a vegetative state,[100] making it potentially useful as
a quantitative assessment of consciousness states.

Assuming that not only humans but even some non-mammalian species are conscious, a number
of evolutionary approaches to the problem of neural correlates of consciousness open up. For
example, assuming that birds are conscious—a common assumption among neuroscientists and
ethologists due to the extensive cognitive repertoire of birds—there are comparative
neuroanatomical ways to validate some of the principal, currently competing, mammalian
consciousness–brain theories. The rationale for such a comparative study is that the avian brain
deviates structurally from the mammalian brain. So how similar are they? What homologues can be
identiﬁed? The general conclusion from the study by Butler, et al.,[101] is that some of the major
theories for the mammalian brain [102][103][104] also appear to be valid for the avian brain. The
structures assumed to be critical for consciousness in mammalian brains have homologous
counterparts in avian brains. Thus the main portions of the theories of Crick and Koch,[102] Edelman
and Tononi,[103] and Cotterill [104] seem to be compatible with the assumption that birds are
conscious. Edelman also differentiates between what he calls primary consciousness (which is a
trait shared by humans and non-human animals) and higher-order consciousness as it appears in
humans alone along with human language capacity.[103] Certain aspects of the three theories,
however, seem less easy to apply to the hypothesis of avian consciousness. For instance, the
suggestion by Crick and Koch that layer 5 neurons of the mammalian brain have a special role,
seems diﬃcult to apply to the avian brain, since the avian homologues have a different morphology.
Likewise, the theory of Eccles[105][106] seems incompatible, since a structural homologue/analogue
to the dendron has not been found in avian brains. The assumption of an avian consciousness also
brings the reptilian brain into focus. The reason is the structural continuity between avian and
reptilian brains, meaning that the phylogenetic origin of consciousness may be earlier than
suggested by many leading neuroscientists.

Joaquin Fuster of UCLA has advocated the position of the importance of the prefrontal cortex in
humans, along with the areas of Wernicke and Broca, as being of particular importance to the
development of human language capacities neuro-anatomically necessary for the emergence of
higher-order consciousness in humans.[107]


Biological function and evolution

Opinions are divided as to where in biological evolution consciousness emerged and about whether
or not consciousness has any survival value. Some argue that consciousness is a byproduct of
evolution. It has been argued that consciousness emerged (i) exclusively with the ﬁrst humans, (ii)
exclusively with the ﬁrst mammals, (iii) independently in mammals and birds, or (iv) with the ﬁrst
reptiles.[108] Other authors date the origins of consciousness to the ﬁrst animals with nervous
systems or early vertebrates in the Cambrian over 500 million years ago.[109] Donald Griﬃn
suggests in his book Animal Minds a gradual evolution of consciousness.[61] Each of these
scenarios raises the question of the possible survival value of consciousness.

Thomas Henry Huxley defends in an essay titled On the Hypothesis that Animals are Automata, and
its History an epiphenomenalist theory of consciousness according to which consciousness is a
causally inert effect of neural activity—“as the steam-whistle which accompanies the work of a
locomotive engine is without inﬂuence upon its machinery”.[110] To this William James objects in his
essay Are We Automata? by stating an evolutionary argument for mind-brain interaction implying
that if the preservation and development of consciousness in the biological evolution is a result of
natural selection, it is plausible that consciousness has not only been inﬂuenced by neural
processes, but has had a survival value itself; and it could only have had this if it had been
eﬃcacious.[111][112] Karl Popper develops in the book The Self and Its Brain a similar evolutionary
argument.[113]

Regarding the primary function of conscious processing, a recurring idea in recent theories is that
phenomenal states somehow integrate neural activities and information-processing that would
otherwise be independent.[114] This has been called the integration consensus. Another example has
been proposed by Gerald Edelman called dynamic core hypothesis which puts emphasis on
reentrant connections that reciprocally link areas of the brain in a massively parallel manner.[115]
Edelman also stresses the importance of the evolutionary emergence of higher-order
consciousness in humans from the historically older trait of primary consciousness which humans
share with non-human animals (see Neural correlates section above). These theories of integrative
function present solutions to two classic problems associated with consciousness: differentiation
and unity. They show how our conscious experience can discriminate between a virtually unlimited
number of different possible scenes and details (differentiation) because it integrates those details
from our sensory systems, while the integrative nature of consciousness in this view easily explains
how our experience can seem uniﬁed as one whole despite all of these individual parts. However, it
remains unspeciﬁed which kinds of information are integrated in a conscious manner and which
kinds can be integrated without consciousness. Nor is it explained what speciﬁc causal role
conscious integration plays, nor why the same functionality cannot be achieved without
consciousness. Obviously not all kinds of information are capable of being disseminated
consciously (e.g., neural activity related to vegetative functions, reﬂexes, unconscious motor
programs, low-level perceptual analyses, etc.) and many kinds of information can be disseminated
and combined with other kinds without consciousness, as in intersensory interactions such as the
ventriloquism effect.[116] Hence it remains unclear why any of it is conscious. For a review of the
differences between conscious and unconscious integrations, see the article of E. Morsella.[116]

As noted earlier, even among writers who consider consciousness to be a well-deﬁned thing, there
is widespread dispute about which animals other than humans can be said to possess it.[117]
Edelman has described this distinction as that of humans possessing higher-order consciousness
while sharing the trait of primary consciousness with non-human animals (see previous paragraph).
Thus, any examination of the evolution of consciousness is faced with great diﬃculties.
Nevertheless, some writers have argued that consciousness can be viewed from the standpoint of
evolutionary biology as an adaptation in the sense of a trait that increases ﬁtness.[118] In his article
"Evolution of consciousness", John Eccles argued that special anatomical and physical properties
of the mammalian cerebral cortex gave rise to consciousness ("[a] psychon ... linked to [a] dendron
through quantum physics").[119] Bernard Baars proposed that once in place, this "recursive" circuitry
may have provided a basis for the subsequent development of many of the functions that
consciousness facilitates in higher organisms.[120] Peter Carruthers has put forth one such potential
adaptive advantage gained by conscious creatures by suggesting that consciousness allows an
individual to make distinctions between appearance and reality.[121] This ability would enable a
creature to recognize the likelihood that their perceptions are deceiving them (e.g. that water in the
distance may be a mirage) and behave accordingly, and it could also facilitate the manipulation of
others by recognizing how things appear to them for both cooperative and devious ends.

Other philosophers, however, have suggested that consciousness would not be necessary for any
functional advantage in evolutionary processes.[122][123] No one has given a causal explanation, they
argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a
philosophical zombie) to achieve the very same survival advantages as a conscious organism. If
evolutionary processes are blind to the difference between function F being performed by
conscious organism O and non-conscious organism O*, it is unclear what adaptive advantage
consciousness could provide.[124] As a result, an exaptive explanation of consciousness has gained
favor with some theorists that posit consciousness did not evolve as an adaptation but was an
exaptation arising as a consequence of other developments such as increases in brain size or
cortical rearrangement.[109] Consciousness in this sense has been compared to the blind spot in the
retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal
axons were wired.[125] Several scholars including Pinker, Chomsky, Edelman, and Luria have
indicated the importance of the emergence of human language as an important regulative
mechanism of learning and memory in the context of the development of higher-order
consciousness (see Neural correlates section above).


States of consciousness




                                         A Buddhist monk

                                         meditating

There are some brain states in which consciousness seems to be absent, including dreamless
sleep, coma, and death. There are also a variety of circumstances that can change the relationship
between the mind and the world in less drastic ways, producing what are known as altered states of
consciousness. Some altered states occur naturally; others can be produced by drugs or brain
damage.[126] Altered states can be accompanied by changes in thinking, disturbances in the sense
of time, feelings of loss of control, changes in emotional expression, alternations in body image and
changes in meaning or signiﬁcance.[127]

The two most widely accepted altered states are sleep and dreaming. Although dream sleep and
non-dream sleep appear very similar to an outside observer, each is associated with a distinct
pattern of brain activity, metabolic activity, and eye movement; each is also associated with a
distinct pattern of experience and cognition. During ordinary non-dream sleep, people who are
awakened report only vague and sketchy thoughts, and their experiences do not cohere into a
continuous narrative. During dream sleep, in contrast, people who are awakened report rich and
detailed experiences in which events form a continuous progression, which may however be
interrupted by bizarre or fantastic intrusions.[128] Thought processes during the dream state
frequently show a high level of irrationality. Both dream and non-dream states are associated with
severe disruption of memory: it usually disappears in seconds during the non-dream state, and in
minutes after awakening from a dream unless actively refreshed.[129]

Research conducted on the effects of partial epileptic seizures on consciousness found that
patients who suffer from partial epileptic seizures experience altered states of
consciousness.[130][131] In partial epileptic seizures, consciousness is impaired or lost while some
aspects of consciousness, often automated behaviors, remain intact. Studies found that when
measuring the qualitative features during partial epileptic seizures, patients exhibited an increase in
arousal and became absorbed in the experience of the seizure, followed by diﬃculty in focusing and
shifting attention.

A variety of psychoactive drugs, including alcohol, have notable effects on consciousness.[132]
These range from a simple dulling of awareness produced by sedatives, to increases in the intensity
of sensory qualities produced by stimulants, cannabis, empathogens–entactogens such as MDMA
("Ecstasy"), or most notably by the class of drugs known as psychedelics.[126] LSD, mescaline,
psilocybin, Dimethyltryptamine, and others in this group can produce major distortions of
perception, including hallucinations; some users even describe their drug-induced experiences as
mystical or spiritual in quality. The brain mechanisms underlying these effects are not as well
understood as those induced by use of alcohol,[132] but there is substantial evidence that alterations
in the brain system that uses the chemical neurotransmitter serotonin play an essential role.[133]

There has been some research into physiological changes in yogis and people who practise various
techniques of meditation. Some research with brain waves during meditation has reported
differences between those corresponding to ordinary relaxation and those corresponding to
meditation. It has been disputed, however, whether there is enough evidence to count these as
physiologically distinct states of consciousness.[134]

The most extensive study of the characteristics of altered states of consciousness was made by
psychologist Charles Tart in the 1960s and 1970s. Tart analyzed a state of consciousness as made
up of a number of component processes, including exteroception (sensing the external world);
interoception (sensing the body); input-processing (seeing meaning); emotions; memory; time
sense; sense of identity; evaluation and cognitive processing; motor output; and interaction with the
environment.[135] Each of these, in his view, could be altered in multiple ways by drugs or other
manipulations. The components that Tart identiﬁed have not, however, been validated by empirical
studies. Research in this area has not yet reached ﬁrm conclusions, but a recent questionnaire-
based study identiﬁed eleven signiﬁcant factors contributing to drug-induced states of
consciousness: experience of unity; spiritual experience; blissful state; insightfulness;
disembodiment; impaired control and cognition; anxiety; complex imagery; elementary imagery;
audio-visual synesthesia; and changed meaning of percepts.[136]


Phenomenology

Phenomenology is a method of inquiry that attempts to examine the structure of consciousness in
its own right, putting aside problems regarding the relationship of consciousness to the physical
world. This approach was ﬁrst proposed by the philosopher Edmund Husserl, and later elaborated
by other philosophers and scientists.[137] Husserl's original concept gave rise to two distinct lines of
inquiry, in philosophy and psychology. In philosophy, phenomenology has largely been devoted to
fundamental metaphysical questions, such as the nature of intentionality ("aboutness"). In
psychology, phenomenology largely has meant attempting to investigate consciousness using the
method of introspection, which means looking into one's own mind and reporting what one
observes. This method fell into disrepute in the early twentieth century because of grave doubts
about its reliability, but has been rehabilitated to some degree, especially when used in combination
with techniques for examining brain activity.[138]




                                         Neon color spreading
                                         effect. The apparent
                                         bluish tinge of the white
                                         areas inside the circle is
                                          an illusion.




                                     Square version of the neon spread
                                     illusion

Introspectively, the world of conscious experience seems to have considerable structure. Immanuel
Kant asserted that the world as we perceive it is organized according to a set of fundamental
"intuitions", which include 'object' (we perceive the world as a set of distinct things); 'shape'; 'quality'
(color, warmth, etc.); 'space' (distance, direction, and location); and 'time'.[139] Some of these
constructs, such as space and time, correspond to the way the world is structured by the laws of
physics; for others the correspondence is not as clear. Understanding the physical basis of qualities,
such as redness or pain, has been particularly challenging. David Chalmers has called this the hard
problem of consciousness.[32] Some philosophers have argued that it is intrinsically unsolvable,
because qualities ("qualia") are ineffable; that is, they are "raw feels", incapable of being analyzed
into component processes.[140] Other psychologists and neuroscientists reject these arguments.
For example, research on ideasthesia shows that qualia are organised into a semantic-like network.
Nevertheless, it is clear that the relationship between a physical entity such as light and a
perceptual quality such as color is extraordinarily complex and indirect, as demonstrated by a
variety of optical illusions such as neon color spreading.[141]

In neuroscience, a great deal of effort has gone into investigating how the perceived world of
conscious awareness is constructed inside the brain. The process is generally thought to involve
two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals
arising from sensory organs are transmitted to the brain and then processed in a series of stages,
which extract multiple types of information from the raw input. In the visual system, for example,
sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex;
inside the cerebral cortex they are sent to areas that extract features such as three-dimensional
structure, shape, color, and motion.[142] Memory comes into play in at least two ways. First, it allows
sensory information to be evaluated in the context of previous experience. Second, and even more
importantly, working memory allows information to be integrated over time so that it can generate a
stable representation of the world—Gerald Edelman expressed this point vividly by titling one of his
books about consciousness The Remembered Present.[143] In computational neuroscience, Bayesian
approaches to brain function have been used to understand both the evaluation of sensory
information in light of previous experience, and the integration of information over time. Bayesian
models of the brain are probabilistic inference models, in which the brain takes advantage of prior
knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian
models have successfully predicted many perceptual phenomena in vision and the nonvisual
senses.[144][145][146]

Despite the large amount of information available, many important aspects of perception remain
mysterious. A great deal is known about low-level signal processing in sensory systems. However,
how sensory systems, action systems, and language systems interact are poorly understood. At a
deeper level, there are still basic conceptual issues that remain unresolved.[142] Many scientists
have found it diﬃcult to reconcile the fact that information is distributed across multiple brain areas
with the apparent unity of consciousness: this is one aspect of the so-called binding problem.[147]
There are also some scientists who have expressed grave reservations about the idea that the brain
forms representations of the outside world at all: inﬂuential members of this group include
psychologist J. J. Gibson and roboticist Rodney Brooks, who both argued in favor of "intelligence
without representation".[148]


Medical aspects

The medical approach to consciousness is practically oriented. It derives from a need to treat
people whose brain function has been impaired as a result of disease, brain damage, toxins, or
drugs. In medicine, conceptual distinctions are considered useful to the degree that they can help to
guide treatments. Whereas the philosophical approach to consciousness focuses on its
fundamental nature and its contents, the medical approach focuses on the amount of
consciousness a person has: in medicine, consciousness is assessed as a "level" ranging from
coma and brain death at the low end, to full alertness and purposeful responsiveness at the high
end.[149]

Consciousness is of concern to patients and physicians, especially neurologists and
anesthesiologists. Patients may suffer from disorders of consciousness, or may need to be
anesthetized for a surgical procedure. Physicians may perform consciousness-related interventions
such as instructing the patient to sleep, administering general anesthesia, or inducing medical
coma.[149] Also, bioethicists may be concerned with the ethical implications of consciousness in
medical cases of patients such as the Karen Ann Quinlan case,[150] while neuroscientists may study
patients with impaired consciousness in hopes of gaining information about how the brain
works.[151]
Assessment

In medicine, consciousness is examined using a set of procedures known as neuropsychological
assessment.[87] There are two commonly used methods for assessing the level of consciousness of
a patient: a simple procedure that requires minimal training, and a more complex procedure that
requires substantial expertise. The simple procedure begins by asking whether the patient is able to
move and react to physical stimuli. If so, the next question is whether the patient can respond in a
meaningful way to questions and commands. If so, the patient is asked for name, current location,
and current day and time. A patient who can answer all of these questions is said to be "alert and
oriented times four" (sometimes denoted "A&Ox4" on a medical chart), and is usually considered
fully conscious.[152]

The more complex procedure is known as a neurological examination, and is usually carried out by
a neurologist in a hospital setting. A formal neurological examination runs through a precisely
delineated series of tests, beginning with tests for basic sensorimotor reﬂexes, and culminating
with tests for sophisticated use of language. The outcome may be summarized using the Glasgow
Coma Scale, which yields a number in the range 3–5, with a score of 3 to 8 indicating coma, and 15
indicating full consciousness. The Glasgow Coma Scale has three subscales, measuring the best
motor response (ranging from "no motor response" to "obeys commands"), the best eye response
(ranging from "no eye opening" to "eyes opening spontaneously") and the best verbal response
(ranging from "no verbal response" to "fully oriented"). There is also a simpler pediatric version of
the scale, for children too young to be able to use language.[149]

In 2013, an experimental procedure was developed to measure degrees of consciousness, the
procedure involving stimulating the brain with a magnetic pulse, measuring resulting waves of
electrical activity, and developing a consciousness score based on the complexity of the brain
activity.[153]


Disorders of consciousness

Medical conditions that inhibit consciousness are considered disorders of consciousness.[154] This
category generally includes minimally conscious state and persistent vegetative state, but
sometimes also includes the less severe locked-in syndrome and more severe chronic
coma.[154][155] Differential diagnosis of these disorders is an active area of biomedical
research.[156][157][158] Finally, brain death results in an irreversible disruption of consciousness.[154]
While other conditions may cause a moderate deterioration (e.g., dementia and delirium) or
transient interruption (e.g., grand mal and petit mal seizures) of consciousness, they are not
included in this category.
    Disorder                                             Description

Locked-in         The patient has awareness, sleep-wake cycles, and meaningful behavior (viz., eye-
syndrome          movement), but is isolated due to quadriplegia and pseudobulbar palsy.

Minimally
                  The patient has intermittent periods of awareness and wakefulness and displays
conscious
                  some meaningful behavior.
state

Persistent
                  The patient has sleep-wake cycles, but lacks awareness and only displays reﬂexive
vegetative
                  and non-purposeful behavior.
state

                  The patient lacks awareness and sleep-wake cycles and only displays reﬂexive
Chronic coma
                  behavior.

                  The patient lacks awareness, sleep-wake cycles, and brain-mediated reﬂexive
Brain death
                  behavior.


Anosognosia
 Main article: Anosognosia

One of the most striking disorders of consciousness goes by the name anosognosia, a Greek-
derived term meaning 'unawareness of disease'. This is a condition in which patients are disabled in
some way, most commonly as a result of a stroke, but either misunderstand the nature of the
problem or deny that there is anything wrong with them.[159] The most frequently occurring form is
seen in people who have experienced a stroke damaging the parietal lobe in the right hemisphere of
the brain, giving rise to a syndrome known as hemispatial neglect, characterized by an inability to
direct action or attention toward objects located to the left with respect to their bodies. Patients
with hemispatial neglect are often paralyzed on the right side of the body, but sometimes deny
being unable to move. When questioned about the obvious problem, the patient may avoid giving a
direct answer, or may give an explanation that doesn't make sense. Patients with hemispatial
neglect may also fail to recognize paralyzed parts of their bodies: one frequently mentioned case is
of a man who repeatedly tried to throw his own paralyzed right leg out of the bed he was lying in,
and when asked what he was doing, complained that somebody had put a dead leg into the bed
with him. An even more striking type of anosognosia is Anton–Babinski syndrome, a rarely
occurring condition in which patients become blind but claim to be able to see normally, and persist
in this claim in spite of all evidence to the contrary.[160]


Stream of consciousness
 Main article: Stream of consciousness (psychology)

William James is usually credited with popularizing the idea that human consciousness ﬂows like a
stream, in his Principles of Psychology of 1890. According to James, the "stream of thought" is
governed by ﬁve characteristics: "(1) Every thought tends to be part of a personal consciousness.
(2) Within each personal consciousness thought is always changing. (3) Within each personal
consciousness thought is sensibly continuous. (4) It always appears to deal with objects
independent of itself. (5) It is interested in some parts of these objects to the exclusion of
others".[161] A similar concept appears in Buddhist philosophy, expressed by the Sanskrit term Citta-
saṃtāna, which is usually translated as mindstream or "mental continuum". Buddhist teachings
describe that consciousness manifests moment to moment as sense impressions and mental
phenomena that are continuously changing.[162] The teachings list six triggers that can result in the
generation of different mental events.[162] These triggers are input from the ﬁve senses (seeing,
hearing, smelling, tasting or touch sensations), or a thought (relating to the past, present or the
future) that happen to arise in the mind. The mental events generated as a result of these triggers
are: feelings, perceptions and intentions/behaviour. The moment-by-moment manifestation of the
mind-stream is said to happen in every person all the time. It even happens in a scientist who
analyses various phenomena in the world, or analyses the material body including the organ
brain.[162] The manifestation of the mindstream is also described as being inﬂuenced by physical
laws, biological laws, psychological laws, volitional laws, and universal laws.[162] The purpose of the
Buddhist practice of mindfulness is to understand the inherent nature of the consciousness and its
characteristics.[163]


Narrative form

In the west, the primary impact of the idea has been on literature rather than science: stream of
consciousness as a narrative mode means writing in a way that attempts to portray the moment-to-
moment thoughts and experiences of a character. This technique perhaps had its beginnings in the
monologues of Shakespeare's plays, and reached its fullest development in the novels of James
Joyce and Virginia Woolf, although it has also been used by many other noted writers.[164]

Here for example is a passage from Joyce's Ulysses about the thoughts of Molly Bloom:


       Yes because he never did a thing like that before as ask to get his breakfast
       in bed with a couple of eggs since the City Arms hotel when he used to be
       pretending to be laid up with a sick voice doing his highness to make
       himself interesting for that old faggot Mrs Riordan that he thought he had
       a great leg of and she never left us a farthing all for masses for herself and
       her soul greatest miser ever was actually afraid to lay out 4d for her
       methylated spirit telling me all her ailments she had too much old chat in
       her about politics and earthquakes and the end of the world let us have a
       bit of fun ﬁrst God help the world if all the women were her sort down on
       bathingsuits and lownecks of course nobody wanted her to wear them I
       suppose she was pious because no man would look at her twice I hope Ill
       never be like her a wonder she didnt want us to cover our faces but she
       was a welleducated woman certainly and her gabby talk about Mr
       Riordan here and Mr Riordan there I suppose he was glad to get shut of
       her.[165]



Spiritual approaches

 Further information: Level of consciousness (esotericism) and Higher consciousness

To most philosophers, the word "consciousness" connotes the relationship between the mind and
the world. To writers on spiritual or religious topics, it frequently connotes the relationship between
the mind and God, or the relationship between the mind and deeper truths that are thought to be
more fundamental than the physical world. The mystical psychiatrist Richard Maurice Bucke
distinguished between three types of consciousness: 'Simple Consciousness', awareness of the
body, possessed by many animals; 'Self Consciousness', awareness of being aware, possessed only
by humans; and 'Cosmic Consciousness', awareness of the life and order of the universe,
possessed only by humans who are enlightened.[166] Many more examples could be given, such as
the various levels of spiritual consciousness presented by Prem Saran Satsangi and Stuart
Hameroff.[167] The most thorough account of the spiritual approach may be Ken Wilber's book The
Spectrum of Consciousness, a comparison of western and eastern ways of thinking about the mind.
Wilber described consciousness as a spectrum with ordinary awareness at one end, and more
profound types of awareness at higher levels.[168]


See also

  Antahkarana                                                   Blindsight

  Being                                                         Causality
 Centipede's dilemma                              Neuropsychological assessment

 Cognitive closure                                Neuropsychology

 Cognitive neuroscience                           New mysterianism

 Cognitive psychology                             Orch-OR

 Chaitanya (consciousness)                        Phenomenology

 Ego                                              Philosophical zombie

 Episodic memory                                  Philosophy of mind

 Explanation                                      Problem of other minds

 Explanatory gap                                  Quantum mind

 Functionalism (philosophy of mind)               Reentry (neural circuitry)

 Hard problem of consciousness                    Reverse engineering

 Ideasthesia                                      Sentience

 Indian psychology                                Solipsism

 Merkwelt                                         Soul

 Mind–body problem                                Spirit

 Mirror neuron                                    Stream of consciousness (psychology)

 Models of Consciousness                          Turing test

 Modularity of mind                               Unconsciousness

 Neural correlates of consciousness

References

 1. "consciousness" . Merriam-Webster. Retrieved June 4, 2012.

 2. Robert van Gulick (2004). "Consciousness" . Stanford Encyclopedia of Philosophy.

 3. Farthing G (1992). The Psychology of Consciousness. Prentice Hall. ISBN 978-0-13-728668-3.

 4. John Searle (2005). "Consciousness". In Honderich T (ed.). The Oxford companion to
   philosophy. Oxford University Press. ISBN 978-0-19-926479-7.

 5. Susan Schneider; Max Velmans (2008). "Introduction". In Max Velmans; Susan Schneider
   (eds.). The Blackwell Companion to Consciousness. Wiley. ISBN 978-0-470-75145-9.
 6. Cohen A.P., Rapport N. (1995). Questions of Consciousness . London: Routledge.
   ISBN 9781134804696.

 7. Trnka R., Lorencova R. (2016). section on consciousness on pp. 33–42 in Quantum
   anthropology: Man, cultures, and groups in a quantum perspective . Prague: Charles University
   Karolinum Press. ISBN 978-80-246-3470-8.

 8. Güven Güzeldere (1997). Ned Block; Owen Flanagan; Güven Güzeldere (eds.). The Nature of
   Consciousness: Philosophical debates. Cambridge, MA: MIT Press. pp. 1–67.

 9. J.J. Fins; N.D. Schiff; K.M. Foley (2007). "Late recovery from the minimally conscious state:
   ethical and policy implications". Neurology. 68 (4): 304–307.
   doi:10.1212/01.wnl.0000252376.43779.96 . PMID 17242341 .

10. Locke, John. "An Essay Concerning Human Understanding (Chapter XXVII)" . Australia:
   University of Adelaide. Retrieved August 20, 2010.

11. "Science & Technology: consciousness" . Encyclopædia Britannica. Retrieved August 20,
   2010.

12. Samuel Johnson (1756). A Dictionary of the English Language . Knapton.

13. Jaucourt, Louis, chevalier de. "Consciousness." The Encyclopedia of Diderot & d'Alembert
   Collaborative Translation Project. Translated by Scott St. Louis. Ann Arbor: Michigan
   Publishing, University of Michigan Library, 2014. Originally published as "Conscience,"
   Encyclopédie ou Dictionnaire raisonné des sciences, des arts et des métiers , 3:902 (Paris,
   1753).

14. C. S. Lewis (1990). "Ch. 8: Conscience and conscious". Studies in words. Cambridge University
   Press. ISBN 978-0-521-39831-2.

15. Thomas Hobbes (1904). Leviathan: or, The Matter, Forme & Power of a Commonwealth,
   Ecclesiasticall and Civill . University Press. p. 39.

16. James Ussher, Charles Richard Elrington (1613). The whole works, Volume 2. Hodges and
   Smith. p. 417.

17. Barbara Cassin (2014). Dictionary of Untranslatables. A Philosophical Lexicon. Princeton
   University Press. p. 176. ISBN 978-0-691-13870-1.

18. G. Molenaar (1969). "Seneca's Use of the Term Conscientia". Mnemosyne. 22 (2): 170–180.
   doi:10.1163/156852569x00670 .

19. Boris Hennig (2007). "Cartesian Conscientia". British Journal for the History of Philosophy. 15
   (3): 455–484. doi:10.1080/09608780701444915 .
20. Charles Adam, Paul Tannery (eds.), Oeuvres de Descartes X, 524     (1908).

21. Sara Heinämaa; Vili Lähteenmäki; Pauliina Remes, eds. (2007). Consciousness: from perception
   to reﬂection in the history of philosophy. Springer. pp. 205–206. ISBN 978-1-4020-6081-6.

22. "CONSCIOUSNESS - meaning in the Cambridge English Dictionary" . dictionary.cambridge.org.

23. "consciousness - Deﬁnition of consciousness in English by Oxford Dictionaries" . Oxford
   Dictionaries - English.

24. Edward Craig (1998). "Consciousness". Routledge Encyclopedia of Philosophy. Routledge.
   ISBN 978-0-415-18707-7.

25. Stuart Sutherland (1989). "Consciousness". Macmillan Dictionary of Psychology. Macmillan.
   ISBN 978-0-333-38829-7.

26. Justin Sytsma; Edouard Machery (2010). "Two conceptions of subjective experience"        (PDF).
   Philosophical Studies. 151 (2): 299–327. doi:10.1007/s11098-009-9439-x .

27. Michael V. Antony (2001). "Is consciousness ambiguous?". Journal of Consciousness Studies.
   8: 19–44.

28. Gilbert Ryle (1949). The Concept of Mind. University of Chicago Press. pp. 156–163. ISBN 978-
   0-226-73296-1.

29. Max Velmans (2009). "How to deﬁne consciousness—and how not to deﬁne consciousness".
   Journal of Consciousness Studies. 16: 139–156.

30. Ned Block (1998). "On a confusion about a function of consciousness" . In N. Block; O.
   Flanagan; G. Guzeldere (eds.). The Nature of Consciousness: Philosophical Debates. MIT Press.
   pp. 375–415. ISBN 978-0-262-52210-6.

31. Daniel Dennett (2004). Consciousness Explained. Penguin. p. 375. ISBN 978-0-7139-9037-9.

32. David Chalmers (1995). "Facing up to the problem of consciousness" . Journal of
   Consciousness Studies. 2: 200–219. Archived from the original      on 2005-03-08.

33. William Lycan (1996). Consciousness and Experience. MIT Press. pp. 1–4. ISBN 978-0-262-
   12197-2.

34. Block N (1995). "How many concepts of consciousness?". Behavioral and Brain Sciences. 18
   (2): 272–284. doi:10.1017/s0140525x00038486 .

35. Dy, Jr., Manuel B. (2001). Philosophy of Man: selected readings. Goodwill Trading Co. p. 97.
   ISBN 978-971-12-0245-3.
36. "Descartes and the Pineal Gland" . Stanford University. November 5, 2008. Retrieved
   2010-08-22.

37. Gert-Jan Lokhorst. Edward N. Zalta (ed.). "Descartes and the pineal gland" . Stanford
   Encyclopedia of Philosophy (Summer 2011 Edition).

38. William Jaworski (2011). Philosophy of Mind: A Comprehensive Introduction. John Wiley and
   Sons. pp. 5–11. ISBN 978-1-4443-3367-1.

39. Julien Offray de La Mettrie (1996). Ann Thomson (ed.). Machine man and other writings.
   Cambridge University Press. ISBN 978-0-521-47849-6.

40. Gerald Edelman (1993). Bright Air, Brilliant Fire: On the Matter of the Mind. Basic Books.
   ISBN 978-0-465-00764-6.

41. Antonio Damasio (1999). The Feeling of What Happens: Body and Emotion in the Making of
   Consciousness. New York: Harcourt Press. ISBN 978-0-15-601075-7.

42. Daniel Dennett (1991). Consciousness Explained. Boston: Little & Company. ISBN 978-0-316-
   18066-5.

43. Christof Koch (2004). The Quest for Consciousness. Englewood, CO: Roberts & Company.
   ISBN 978-0-9747077-0-9.

44. Ron Sun and Stan Franklin, Computational models of consciousness: A taxonomy and some
   examples. In: P.D. Zelazo, M. Moscovitch, and E. Thompson (eds.), The Cambridge Handbook of
   Consciousness, pp. 151–174. Cambridge University Press, New York. 2007

45. "Quantum Approaches to Consciousness" . Stanford University. December 25, 2011.

46. Cai, J.; Popescu, S.; Briegel, H. (2010). "Persistent dynamic entanglement from classical
   motion: How bio-molecular machines can generate non-trivial quantum states". Physical
   Review E. 82 (2): 021921. arXiv:0809.4906 . Bibcode:2010PhRvE..82b1921C .
   doi:10.1103/PhysRevE.82.021921 . PMID 20866851 .

47. John Searle (1997). The Mystery of Consciousness. The New York Review of Books. pp. 53–88.
   ISBN 978-0-940322-06-6.

48. For a discussion see Rocco J. Gennaro (2011). "§4.4 The hard problem of consciousness" .
   The Consciousness Paradox: Consciousness, Concepts, and Higher-Order Thoughts. MIT Press.
   p. 75. ISBN 978-0-262-01660-5.

49. Knobe J (2008). "Can a Robot, an Insect or God Be Aware?" . Scientiﬁc American Mind. 19 (6):
   68–71. doi:10.1038/scientiﬁcamericanmind1208-68 .

50. Alec Hyslop (1995). Other Minds. Springer. pp. 5–14. ISBN 978-0-7923-3245-9.
51. Robert Kirk. Edward N. Zalta (ed.). "Zombies" . Stanford Encyclopedia of Philosophy (Summer
   2009 Edition).

52. The Culture and Philosophy of Ridley Scott, Greg Littmann, pp. 133–144, Lexington Books
   (2013).

53. Moral Machines, Wendell Wallach and Colin Allen, 288 pages, Oxford University Press, USA
   (June 3, 2010), ISBN 0-19-973797-5.

54. Alec Hyslop (1995). "The analogical inference to other minds". Other Minds. Springer. pp. 41–
   70. ISBN 978-0-7923-3245-9.

55. Daniel Dennett (1995). "The unimagined preposterousness of zombies". Journal of
   Consciousness Studies. 2: 322–325.

56. Stevan Harnad (1995). "Why and how we are not zombies". Journal of Consciousness Studies.
   1: 164–167.

57. Colin Allen. Edward N. Zalta (ed.). "Animal consciousness" . Stanford Encyclopedia of
   Philosophy (Summer 2011 Edition).

58. Peter Carruthers (1999). "Sympathy and subjectivity". Australasian Journal of Philosophy. 77
   (4): 465–482. doi:10.1080/00048409912349231 .

59. Thomas Nagel (1991). "Ch. 12 What is it like to be a bat?". Mortal Questions. Cambridge
   University Press. ISBN 978-0-521-40676-5.

60. Douglas Hofstadter (1981). "Reﬂections on What Is It Like to Be a Bat?". In Douglas Hofstadter;
   Daniel Dennett (eds.). The Mind's I. Basic Books. pp. 403–414. ISBN 978-0-7108-0352-8.

61. Donald Griﬃn (2001). Animal Minds: Beyond Cognition to Consciousness. University of Chicago
   Press. ISBN 978-0-226-30865-4.

62. Animal Consciousness Oﬃcially Recognized by Leading Panel of Neuroscientists . 3 September
   2012 – via YouTube.

63. "Cambridge Declaration on Consciousness"       (PDF).

64. Moshe Idel (1990). Golem: Jewish Magical and Mystical Traditions on the Artiﬁcial Anthropoid.
   SUNY Press. ISBN 978-0-7914-0160-6. Note: In many stories the Golem was mindless, but
   some gave it emotions or thoughts.

65. Ada Lovelace. "Sketch of The Analytical Engine, Note G" .

66. Stuart Shieber (2004). The Turing Test : Verbal Behavior as the Hallmark of Intelligence. MIT
   Press. ISBN 978-0-262-69293-9.
67. Daniel Dennett; Douglas Hofstadter (1985). The Mind's I. Basic Books. ISBN 978-0-553-34584-
   1.

68. David Chalmers (1997). The Conscious Mind: In Search of a Fundamental Theory. Oxford
   University Press. ISBN 978-0-19-511789-9.

69. Jürgen Schmidhuber (2009). Driven by Compression Progress: A Simple Principle Explains
   Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity,
   Creativity, Art, Science, Music, Jokes.

70. John R. Searle (1990). "Is the brain's mind a computer program"      (PDF). Scientiﬁc American.
   262 (1): 26–31. Bibcode:1990SciAm.262a..26S . doi:10.1038/scientiﬁcamerican0190-26 .
   PMID 2294583 .

71. "The Chinese Room Argument" .

72. John Searle; et al. (1980). "Minds, brains, and programs". Behavioral and Brain Sciences. 3 (3):
   417–457. CiteSeerX 10.1.1.83.5248 . doi:10.1017/S0140525X00005756 .

73. Graham Oppy; David Dowe (2011). "The Turing test" . Stanford Encyclopedia of Philosophy
   (Spring 2011 Edition).

74. Margaret Wilson (2002). "Six views of embodied cognition" . Psychonomic Bulletin & Review. 9
   (4): 625–636. doi:10.3758/BF03196322 . Archived from the original           on 2011-09-27.

75. Victor Argonov (2014). "Experimental Methods for Unraveling the Mind-body Problem: The
   Phenomenal Judgment Approach" . Journal of Mind and Behavior. 35: 51–70.

76. Horst Hendriks-Jansen (1996). Catching ourselves in the act: situated activity, interactive
   emergence, evolution, and human thought. Massachusetts Institute of Technology. p. 114.
   ISBN 978-0-262-08246-4.

77. Mandler, G. "Consciousness: Respectable, useful, and probably necessary". In R. Solso (Ed.)
   Information processing and cognition: NJ: LEA.

78. Mandler, G. Consciousness recovered: Psychological functions and origins of thought.
   Philadelphia: John Benjamins. 2002

79. Stuart Hameroff; Alfred Kaszniak; David Chalmers (1999). "Preface". Toward a Science of
   Consciousness III: The Third Tucson Discussions and Debates. MIT Press. pp. xix–xx. ISBN 978-
   0-262-58181-3.

80. Bernard Baars (1993). A Cognitive Theory of Consciousness. Cambridge University Press.
   pp. 15–18. ISBN 978-0-521-42743-2.
81. Paul Rooks; Jane Wilson (2000). Perception: Theory, Development, and Organization.
   Psychology Press. pp. 25–26. ISBN 978-0-415-19094-7.

82. Thomas Schmidt; Dirk Vorberg (2006). "Criteria for unconscious cognition: Three types of
   dissociation". Perception and Psychophysics. 68 (3): 489–504. doi:10.3758/bf03193692 .
   PMID 16900839 .

83. Arnaud Destrebecqz; Philippe Peigneux (2006). "Methods for studying unconscious learning".
   In Steven Laureys (ed.). The Boundaries of Consciousness: Neurobiology and Neuropathology.
   Elsevier. pp. 69–80. ISBN 978-0-444-52876-6.

84. Daniel Dennett (1992). "Quining qualia" . In A. Marcel; E. Bisiach (eds.). Consciousness in
   Modern Science. Oxford University Press. ISBN 978-0-19-852237-9. Retrieved 2011-10-31.

85. Daniel Dennett (2003). "Who's on ﬁrst? Heterophenomenology explained". Journal of
   Consciousness Studies. 10: 19–30.

86. David Chalmers (1996). "Ch. 3: Can consciousness be reductively explained?". The Conscious
   Mind. Oxford University Press. ISBN 978-0-19-511789-9.

87. J.T. Giacino; C.M. Smart (2007). "Recent advances in behavioral assessment of individuals
   with disorders of consciousness". Current Opinion in Neurology. 20 (6): 614–619.
   doi:10.1097/WCO.0b013e3282f189ef . PMID 17992078 .

88. Patrick Haggard (2008). "Human volition: towards a neuroscience of will". Nature Reviews
   Neuroscience. 9 (12): 934–946. doi:10.1038/nrn2497 . PMID 19020512 .

89. Gordon Gallup (1970). "Chimpanzees: Self recognition". Science. 167 (3914): 86–87.
   Bibcode:1970Sci...167...86G . doi:10.1126/science.167.3914.86 . PMID 4982211 .

90. David Edelman; Anil Seth (2009). "Animal consciousness: a synthetic approach". Trends in
   Neurosciences. 32 (9): 476–484. doi:10.1016/j.tins.2009.05.008 . PMID 19716185 .

91. Christof Koch (2004). The Quest for Consciousness. Englewood, CO: Roberts & Company.
   pp. 16–19. ISBN 978-0-9747077-0-9.

92. Wolf Singer. "Binding by synchrony" . Scholarpedia. Retrieved 2011-10-26.

93. Rodolfo Llinás (2002). I of the vortex: from neurons to self. MIT Press. ISBN 978-0-262-62163-2.

94. Koch, The Quest for Consciousness, pp. 105–116

95. Francis Crick; Christof Koch (2003). "A framework for consciousness"     (PDF). Nature
   Neuroscience. 6 (2): 119–126. doi:10.1038/nn0203-119 . PMID 12555104 . Archived from
   the original   (PDF) on 2012-05-22.
 96. Koch, The Quest for Consciousness, pp. 269–286

 97. Biederlack J.; Castelo-Branco M.; Neuenschwander S.; Wheeler D.W.; Singer W.; Nikolić D.
     (2006). "Brightness induction: Rate enhancement and neuronal synchronization as
     complementary codes". Neuron. 52 (6): 1073–1083. doi:10.1016/j.neuron.2006.11.012 .
     PMID 17178409 .

 98. Williams Adrian L.; Singh Krishna D.; Smith Andrew T. (2003). "Surround modulation measured
     with functional MRI in the human visual cortex". Journal of Neurophysiology. 89 (1): 525–533.
     CiteSeerX 10.1.1.137.1066 . doi:10.1152/jn.00048.2002 . PMID 12522199 .

 99. Graziano, M.S.A.; Kastner, S (2011). "Human consciousness and its relationship to social
     neuroscience: A novel hypothesis" . Cog. Neurosci. 2 (2): 98–113.
     doi:10.1080/17588928.2011.565121 . PMC 3223025 . PMID 22121395 .

100. Adenauer G. Casali; Olivia Gosseries; Mario Rosanova; Mélanie Boly; Simone Sarasso; Karina R.
     Casali; Silvia Casarotto; Marie-Aurélie Bruno; Steven Laureys; Giulio Tononi; Marcello
     Massimini (14 August 2013). "A Theoretically based index of consciousness independent of
     sensory processing and behavior" . Science Translational Medicine. 5 (198): 198ra105.
     doi:10.1126/scitranslmed.3006294 . PMID 23946194 .

101. Ann B. Butler; Paul R. Manger; B.I.B Lindahl; Peter Århem (2005). "Evolution of the neural basis
     of consciousness: a bird-mammal comparison". BioEssays. 27 (9): 923–936.
     doi:10.1002/bies.20280 . PMID 16108067 .

102. Francis Crick and Christof Koch (1995). "Are we aware of neural activity in primary visual
     cortex?". Nature. 375 (6527): 121–123. Bibcode:1995Natur.375..121C .
     doi:10.1038/375121a0 . PMID 7753166 .

103. Gerald M. Edelman and Giulio Tononi (2000). A Universe of Consciousness: How Matter
     Becomes Imagination. Basic Books. ISBN 978-0-465-01376-0.

104. Rodney M.J. Cotterill (2001). "Cooperation of the basal ganglia, cerebellum, sensory cerebrum
     and hippocampus: possible implications for cognition, consciousness, intelligence and
     creativity". Progress in Neurobiology. 64 (1): 1–33. doi:10.1016/s0301-0082(00)00058-7 .
     PMID 11250060 .

105. J.C. Eccles (1982). "Animal consciousness and human self-consciousness". Experientia. 38
     (12): 1384–1391. doi:10.1007/bf01955747 .

106. John Eccles (1990). "A unitary hypothesis of mind-brain interaction in the cerebral cortex".
     Proceedings of the Royal Society of London B. 240 (1299): 433–451.
     Bibcode:1990RSPSB.240..433E . doi:10.1098/rspb.1990.0047 .
107. Joaquin Fuster, The Prefrontal Cortex, Second Edition.

108. Peter Århem; B.I.B. Lindahl; Paul R. Manger; Ann B. Butler (2008). "On the origin of
     consciousness—some amniote scenarios" . In Hans Liljenström; Peter Århem (eds.).
     Consciousness Transitions: Phylogenetic, Ontogenetic, and Physiological Aspects. Elsevier.
     ISBN 978-0-444-52977-0.

109. Feinberg, TE; Mallatt, J (October 2013). "The evolutionary and genetic origins of consciousness
     in the Cambrian Period over 500 million years ago" . Frontiers in Psychology. 4: 667.
     doi:10.3389/fpsyg.2013.00667 . PMC 3790330 . PMID 24109460 .

110. T.H. Huxley (1874). "On the hypothesis that animals are automata, and its history". The
     Fortnightly Review. 16: 555–580.

111. W. James (1879). "Are we automata?". Mind. 4 (13): 1–22. doi:10.1093/mind/os-4.13.1 .

112. B.I.B. Lindahl (1997). "Consciousness and biological evolution". Journal of Theoretical Biology.
     187 (4): 613–629. doi:10.1006/jtbi.1996.0394 .

113. Karl R. Popper, John C. Eccles (1977). The Self and Its Brain. Springer International. ISBN 978-
     0-387-08307-0.

114. Bernard Baars (January 2002). "The conscious access hypothesis: Origins and recent
     evidence". Trends in Cognitive Sciences. 6 (1): 47–52. doi:10.1016/S1364-6613(00)01819-2 .
     PMID 11849615 .

115. Seth, Anil; Eugene Izhikevich; George Reeke; Gerald Edelman (2006). "Theories and measures
     of consciousness: An extended framework" . Proceedings of the National Academy of
     Sciences. 103 (28): 10799–10804. Bibcode:2006PNAS..10310799S .
     doi:10.1073/pnas.0604347103 . PMC 1487169 . PMID 16818879 .

116. Ezequiel Morsella (2005). "The function of phenomenal states: Supramodular Interaction
     Theory". Psychological Review. 112 (4): 1000–1021. doi:10.1037/0033-295X.112.4.1000 .
     PMID 16262477 .

117. S. Budiansky (1998). If a Lion Could Talk: Animal Intelligence and the Evolution of
     Consciousness. The Free Press. ISBN 978-0-684-83710-9.

118. S. Nichols; T. Grantham (2000). "Adaptive Complexity and Phenomenal Consciousness"
     (PDF). Philosophy of Science. 67 (4): 648–670. CiteSeerX 10.1.1.515.9722 .
     doi:10.1086/392859 .

119. John Eccles (1992). "Evolution of consciousness" . Proc. Natl. Acad. Sci. USA. 89 (16): 7320–
     7324. Bibcode:1992PNAS...89.7320E . doi:10.1073/pnas.89.16.7320 . PMC 49701 .
     PMID 1502142 .
120. Bernard Baars (1993). A Cognitive Theory of Consciousness. Cambridge University Press.
     ISBN 978-0-521-42743-2.

121. Carruthers, Peter (2004). Phenomenal Consciousness: A Naturalistic Theory. Cambridge:
     Cambridge University Press.

122. Owen Flanagan; T.W. Polger (1995). "Zombies and the function of consciousness". Journal of
     Consciousness Studies. 2: 313–321.

123. Rosenthal, David (2008). "Consciousness and its function". Neuropsychologia. 46 (3): 829–840.
     doi:10.1016/j.neuropsychologia.2007.11.012 . PMID 18164042 .

124. Stevan Harnad (2002). "Turing indistinguishability and the Blind Watchmaker" . In J.H. Fetzer
     (ed.). Consciousness Evolving. John Benjamins. Retrieved 2011-10-26.

125. Zack Robinson; Corey J. Maley; Gualtiero Piccinini (2015). "Is Consciousness a Spandrel?".
     Journal of the American Philosophical Association. 1 (2): 365–383. doi:10.1017/apa.2014.10 .

126. Dieter Vaitl; et al. (2005). "Psychobiology of altered states of consciousness". Psychological
     Bulletin. 131 (1): 98–127. doi:10.1037/0033-2909.131.1.98 . PMID 15631555 .

127. Schacter, Daniel; Gilbert, Daniel; Wegner, Daniel (2011). Psychology 2nd Ed. New York: Worth
     Publishers. p. 190. ISBN 978-1-4292-3719-2.

128. Anton Coenen (2010). "Subconscious Stimulus Recognition and Processing During Sleep" .
     Psyche. 16–2.

129. J. Allan Hobson; Edward F. Pace-Schott; Robert Stickgold (2003). "Dreaming and the brain:
     Toward a cognitive neuroscience of conscious states". In Edward F. Pace-Schott; Mark Solms;
     Mark Blagrove; Stevan Harnad (eds.). Sleep and Dreaming: Scientiﬁc Advances and
     Reconsiderations. Cambridge University Press. ISBN 978-0-521-00869-3.

130. Johanson, M., Valli, K., Revonsuo, A., & Wedlund, J., 2008. Content analysis of subjective
     experiences in partial epileptic seizures. Epilepsy & Behavior, 12, pp. 170–182

131. Johanson M.; Valli K.; Revonsuo A.; et al. (2008). "Alterations in the contents of consciousness
     in partial epileptic seizures". Epilepsy & Behavior. 13 (2): 366–371.
     doi:10.1016/j.yebeh.2008.04.014 . PMID 18522873 .

132. Diagnostic and statistical manual of mental disorders: DSM-IV . Washington, DC: American
     Psychiatric Association. 31 July 1994. ISBN 978-0-89042-025-6.

133. Michael Lyvers (2003). "The neurochemistry of psychedelic experiences"       (PDF).
     ePublications@bond.
134. M. Murphy; S. Donovan; E. Taylor (1997). The Physical and Psychological Effects of Meditation:
     A Review of Contemporary Research With a Comprehensive Bibliography, 1931–1996. Institute of
     Noetic Sciences.

135. Charles Tart (2001). "Ch. 2: The components of consciousness" . States of Consciousness.
     IUniverse.com. ISBN 978-0-595-15196-7. Retrieved 2011-10-05.

136. E. Studerus; A. Gamma; F.X. Vollenweider (2010). "Psychometric evaluation of the altered
     states of consciousness rating scale (OAV)" . PLoS ONE. 5 (8): e12412.
     Bibcode:2010PLoSO...512412S . doi:10.1371/journal.pone.0012412 . PMC 2930851 .
     PMID 20824211 .

137. Robert Sokolowski (2000). Introduction to Phenomenology. Cambridge University Press.
     pp. 211–227. ISBN 978-0-521-66792-0.

138. K. Anders Ericsson (2003). "Valid and non-reactive verbalization of thoughts during
     performance of tasks: towards a solution to the central problems of introspection as a source
     of scientiﬁc evidence". In Anthony Jack; Andreas Roepstorff (eds.). Trusting the Subject?: The
     Use of Introspective Evidence in Cognitive Science, Volume 1. Imprint Academic. pp. 1–18.
     ISBN 978-0-907845-56-0.

139. Andrew Brook. "Kant's view of the mind and consciousness of self" . Stanford Encyclopedia of
     Philosophy. Note: translating Kant's terminology into English is often diﬃcult.

140. Joseph Levine (1998). "On leaving out what it's like". In N. Block; O. Flanagan; G. Guzeldere
     (eds.). The Nature of Consciousness: Philosophical Debates. MIT Press. ISBN 978-0-262-52210-
     6.

141. Steven K. Shevell (2003). "Color appearance". In Steven K. Shevell (ed.). The Science of Color.
     Elsevier. pp. 149–190. ISBN 978-0-444-51251-2.

142. Bennett, M.R. (2003). Peter Michael; Stephan Hacker (eds.). Philosophical Foundations of
     Neuroscience. Wiley-Blackwell. pp. 121–147. ISBN 978-1-4051-0838-6.

143. Gerald Edelman (1989). The Remembered Present: A Biological Theory of Consciousness. Basic
     Books. pp. 109–118. ISBN 978-0-465-06910-1.

144. Knill DC (2007). "Learning Bayesian priors for depth perception" . Journal of Vision. 7 (8): 1–
     20. doi:10.1167/7.8.13 . PMID 17685820 .

145. Battaglia PW, Jacobs RA, Aslin RN (2003). "Bayesian integration of visual and auditory signals
     for spatial localization" . Journal of the Optical Society of America. 20 (7): 1391–1397.
     Bibcode:2003JOSAA..20.1391B . doi:10.1364/josaa.20.001391 .
146. Goldreich, Daniel; Tong, Jonathan (10 May 2013). "Prediction, Postdiction, and Perceptual
     Length Contraction: A Bayesian Low-Speed Prior Captures the Cutaneous Rabbit and Related
     Illusions". Frontiers in Psychology. 4 (221). doi:10.3389/fpsyg.2013.00221 .
     PMID 23675360 .

147. Koch, The Quest for Consciousness, pp. 167–170

148. Rodney Brooks (1991). "Intelligence without representation". Artiﬁcial Intelligence. 47 (1–3):
     139–159. CiteSeerX 10.1.1.308.6537 . doi:10.1016/0004-3702(91)90053-M .

149. Hal Blumenfeld (2009). "The neurological examination of consciousness". In Steven Laureys;
     Giulio Tononi (eds.). The Neurology of Consciousness: Cognitive Neuroscience and
     Neuropathology. Academic Press. ISBN 978-0-12-374168-4.

150. Kinney HC, Korein J, Panigrahy A, Dikkes P, Goode R (26 May 1994). "Neuropathological
     ﬁndings in the brain of Karen Ann Quinlan – the role of the thalamus in the persistent
     vegetative state". N Engl J Med. 330 (21): 1469–1475. doi:10.1056/NEJM199405263302101 .
     PMID 8164698 .

151. Koch, The Quest for Consciousness, pp. 216–226

152. V. Mark Durand; David H. Barlow (2009). Essentials of Abnormal Psychology. Cengage Learning.
     pp. 74–75. ISBN 978-0-495-59982-1. Note: A patient who can additionally describe the current
     situation may be referred to as "oriented times four".

153. Neergaard, Lauren (August 14, 2013). "New tool peeks into brain to measure consciousness" .
     Associated Press through NBC News. Archived from the original       on August 15, 2013.

154. Bernat JL (8 Apr 2006). "Chronic disorders of consciousness". Lancet. 367 (9517): 1181–1192.
     doi:10.1016/S0140-6736(06)68508-5 . PMID 16616561 .

155. Bernat JL (20 Jul 2010). "The natural history of chronic disorders of consciousness".
     Neurology. 75 (3): 206–207. doi:10.1212/WNL.0b013e3181e8e960 . PMID 20554939 .

156. Coleman MR, Davis MH, Rodd JM, Robson T, Ali A, Owen AM, Pickard JD (September 2009).
     "Towards the routine use of brain imaging to aid the clinical diagnosis of disorders of
     consciousness". Brain. 132 (9): 2541–2552. doi:10.1093/brain/awp183 . PMID 19710182 .

157. Monti MM, Vanhaudenhuyse A, Coleman MR, Boly M, Pickard JD, Tshibanda L, Owen AM,
     Laureys S (18 Feb 2010). "Willful modulation of brain activity in disorders of consciousness". N
     Engl J Med. 362 (7): 579–589. doi:10.1056/NEJMoa0905370 . PMID 20130250 .
158. Seel RT, Sherer M, Whyte J, Katz DI, Giacino JT, Rosenbaum AM, Hammond FM, Kalmar K, Pape
     TL, et al. (December 2010). "Assessment scales for disorders of consciousness: evidence-
     based recommendations for clinical practice and research". Arch Phys Med Rehabil. 91 (12):
     1795–1813. doi:10.1016/j.apmr.2010.07.218 . PMID 21112421 .

159. George P. Prigatano; Daniel Schacter (1991). "Introduction". In George Prigatano; Daniel
     Schacter (eds.). Awareness of Deﬁcit After Brain Injury: Clinical and Theoretical Issues. Oxford
     University Press. pp. 3–16. ISBN 978-0-19-505941-0.

160. Kenneth M. Heilman (1991). "Anosognosia: possible neuropsychological mechanisms". In
     George Prigatano; Daniel Schacter (eds.). Awareness of Deﬁcit After Brain Injury: Clinical and
     Theoretical Issues. Oxford University Press. pp. 53–62. ISBN 978-0-19-505941-0.

161. William James (1890). The Principles of Psychology, Volume 1. H. Holt. p. 225.

162. Karunamuni N.D. (May 2015). "The Five-Aggregate Model of the Mind"         (PDF). Sage Open. 5
     (2): 215824401558386. doi:10.1177/2158244015583860 .

163. Dzogchen Rinpoche (2007). "Taming the mindstream". In Doris Wolter (ed.). Losing the Clouds,
     Gaining the Sky: Buddhism and the Natural Mind. Wisdom Publications. pp. 81–92. ISBN 978-0-
     86171-359-2.

164. Robert Humphrey (1954). Stream of Consciousness in the Modern Novel. University of
     California Press. pp. 23–49. ISBN 978-0-520-00585-3.

165. James Joyce (1990). Ulysses. BompaCrazy.com. p. 620.

166. Richard Maurice Bucke (1905). Cosmic Consciousness: A Study in the Evolution of the Human
     Mind . Innes & Sons. pp. 1–2.

167. Satsangi, Prem Saran and Hameroff, Stuart (2016) Consciousness: Integrating Eastern and
     Western Perspectives    New Age Books. ISBN 978-81-7822-493-0

168. Ken Wilber (2002). The Spectrum of Consciousness. Motilal Banarsidass. pp. 3–16. ISBN 978-
     81-208-1848-4.

Further reading

  Susan Blackmore, "The Hardest Problem: Decoding the puzzle of human consciousness",
  Scientiﬁc American, vol. 319, no. 3 (September 2018), pp. 48–53.

  Karl J Friston, The mathematics of mind-time , Aeon, (May 2017)

  Anil Seth, The Real Problem , Aeon, (November 2016)
 Antonio Damasio (2012). Self Comes to Mind: Constructing the Conscious Brain. Vintage.
 ISBN 978-0-307-47495-7.

 Philip David Zelazo; Morris Moscovitch; Evan Thompson (2007). The Cambridge Handbook of
 Consciousness. Cambridge University Press. ISBN 978-0-521-67412-6.

 Kak, Subhash (2002) "The Gods Within: Mind, Consciousness and the Vedic Tradition" ,
 Munshiram Manoharlal. ISBN 81-215-1063-5

 The Origin of Consciousness in the Breakdown of the Bicameral Mind
 https://www.amazon.com/dp/0618057072/ref=cm_sw_r_cp_api_USoEBbWVJ5XNM

External links

 Wikiquote has quotations related to: Consciousness


 Wikimedia Commons has media related to Consciousness.

   The dictionary deﬁnition of consciousness at Wiktionary

   Consciousness Studies at Wikibooks

 Giubilini, Alberto. "Conscience" . In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.

 Gulick, Robert Van. "Consciousness" . In Zalta, Edward N. (ed.). Stanford Encyclopedia of
 Philosophy.

 "Consciousness" . Internet Encyclopedia of Philosophy.


   Last edited 10 hours ago by Gcascas
